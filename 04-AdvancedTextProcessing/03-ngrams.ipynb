{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run first the [setup notebook](./00-setup.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-gram extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import get_book\n",
    "book = get_book(244)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive approach: create bi-grams, count frequencies in text, then pick top-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.collocations import (\n",
    "    BigramCollocationFinder, BigramAssocMeasures,  \n",
    "    TrigramCollocationFinder, TrigramAssocMeasures,  \n",
    "    QuadgramCollocationFinder, QuadgramAssocMeasures\n",
    ")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "ignored_words = stopwords.words('english')\n",
    "stopword_filter = lambda w: len(w) < 3 or w.lower() in ignored_words\n",
    "\n",
    "nResults = 20\n",
    "\n",
    "def ngram_measures(n: int, metric: str):\n",
    "    measure = BigramAssocMeasures\n",
    "    if n == 3: measure = TrigramAssocMeasures\n",
    "    if n == 4: measure = QuadgramAssocMeasures\n",
    "    if metric == 'freq': return measure.raw_freq\n",
    "    if metric == 'pmi': return measure.pmi\n",
    "    return measure.likelihood_ratio\n",
    "\n",
    "def ngrams_from_words(n: int, tokens: list[str]):\n",
    "    if n == 3: return TrigramCollocationFinder.from_words(tokens)\n",
    "    if n == 4: return QuadgramCollocationFinder.from_words(tokens)\n",
    "    return BigramCollocationFinder.from_words(tokens)\n",
    "\n",
    "def ngrams_result(n: int, finder, scores, metric: str):\n",
    "    if n == 3:\n",
    "        headers = ['trigram', f'frequency']\n",
    "        rows = [[' '.join([t1,t2,t3]),  score] for ((t1,t2,t3),score) in scores]\n",
    "        # headers = ['trigram', 'tf(w1)', 'tf(w2)', 'tf(w3)', 'tf(trigram)', f'score ({metric})']\n",
    "        # rows = [[' '.join([t1,t2,t3]), finder.word_fd[t1], finder.word_fd[t2], finder.word_fd[t3], finder.ngram_fd[(t1,t2,t3)], score] for ((t1,t2,t3),score) in scores]\n",
    "        return (headers, rows)\n",
    "    if n == 4:\n",
    "        headers = ['quadgram', 'tf(w1)', 'tf(w2)', 'tf(w3)', 'tf(w4)', 'tf(quadgram)', f'score ({metric})']\n",
    "        rows = [[' '.join([t1,t2,t3,t4]), finder.word_fd[t1], finder.word_fd[t2], finder.word_fd[t3], finder.word_fd[t4], finder.ngram_fd[(t1,t2,t3,t4)], score] for ((t1,t2,t3,t4),score) in scores]\n",
    "        return (headers, rows)\n",
    "    headers = ['bigram', 'tf(w1)', 'tf(w2)', 'tf(bigram)', f'score ({metric})']\n",
    "    rows = [[' '.join([t1,t2]), finder.word_fd[t1], finder.word_fd[t2], finder.ngram_fd[(t1,t2)], score] for ((t1,t2),score) in scores]\n",
    "    return (headers, rows)\n",
    "\n",
    "def ngrams(tokens: list[str], n: int, metric: str, filters: list[str]) -> tuple[list[str],list[list[str]]]:\n",
    "    measure = ngram_measures(n, metric)\n",
    "    finder = ngrams_from_words(n, tokens)\n",
    "    for f in filters:\n",
    "        if f == 'freq3': finder.apply_freq_filter(3)\n",
    "        if f == 'freq5': finder.apply_freq_filter(5)\n",
    "        if f == 'stopwords': finder.apply_word_filter(stopword_filter)\n",
    "    scores = finder.score_ngrams(measure)[:nResults]\n",
    "    return ngrams_result(n, finder, scores, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d9835f6e81409d80adeb096663f509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='book', options=(('A Study in Scarlet (en)', 244), ('Buddenbrooks: â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "from tabulate import tabulate\n",
    "\n",
    "last_book = 0\n",
    "tokens = []\n",
    "\n",
    "def show_ngrams(book, n, metric, stopwords, freq3, freq5):\n",
    "    global last_book, tokens\n",
    "    if last_book != book:\n",
    "        tokens = [token for token in nltk.word_tokenize(get_book(book).page_content) if token.isalpha()]\n",
    "        last_book = book\n",
    "    headers, rows = ngrams(tokens, n, metric, [stopwords and 'stopwords', freq3 and 'freq3', freq5 and 'freq5'])\n",
    "    display(Markdown(tabulate(rows, headers, \"pipe\")))\n",
    "\n",
    "opt_book = widgets.Dropdown(description='book', options=[\n",
    "    ('A Study in Scarlet (en)', 244),\n",
    "    ('Buddenbrooks: Verfall einer Familie (de)', 34811),\n",
    "    ('Les trois mousquetaires (fr)', 13951),\n",
    "    ('Bajki (pl)', 27729),\n",
    "])\n",
    "opt_metric = widgets.Dropdown(description='metric', options=['freq', 'pmi', 'lhr'])\n",
    "opt_n = widgets.BoundedIntText(description='n', value=2, min=2, max=4)\n",
    "opt_stopword = widgets.Checkbox(description='no stopwords')\n",
    "opt_freq3 = widgets.Checkbox(description='freq > 3')\n",
    "opt_freq5 = widgets.Checkbox(description='freq > 5')\n",
    "\n",
    "display(widgets.interactive(show_ngrams, book=opt_book, n=opt_n ,metric=opt_metric, stopwords=opt_stopword, freq3=opt_freq3, freq5=opt_freq5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual calclualtions of PMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.070154495134162"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "N = len(tokens)\n",
    "tf1, tf2, tf12 = 5, 5, 5\n",
    "p1, p2, p12 = tf1/N, tf2/N, tf12/N\n",
    "math.log(p12/p1/p2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual calulcation of LHR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "618.2639397345096"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1=48\n",
    "c2=94\n",
    "c12=48\n",
    "p=c2/N\n",
    "p1=c12/c1\n",
    "p2=(c2-c12)/(N-c1)\n",
    "def L(k,n,p):\n",
    "    return (p**k)*(1-p)**(n-k)\n",
    "-2*(math.log(L(c12,c1,p))+math.log(L(c2-c12,N-c1,p))-math.log(L(c12,c1,p1))-math.log(L(c2-c12,N-c1,p2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple summary of bi-gram calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sherlock Holmes 48 94 48 618.2639397345179\n",
      "Jefferson Hope 37 42 34 491.94785591179664\n",
      "John Ferrier 31 58 26 330.1825164533987\n",
      "Brixton Road 15 13 13 224.92059705760528\n",
      "Salt Lake 9 9 9 170.48968950333003\n",
      "Lake City 9 13 8 129.82912069112837\n",
      "Enoch Drebber 9 62 9 119.12601098633465\n",
      "Scotland Yard 8 6 6 109.52843062923058\n",
      "Baker Street 6 11 6 103.36758969662593\n",
      "Private Hotel 5 5 5 100.59482597348887\n",
      "Lucy Ferrier 29 58 10 96.68084062615573\n",
      "Lauriston Gardens 4 4 4 82.26110221688567\n",
      "Joseph Stangerson 13 43 7 79.9799404000117\n",
      "Never mind 5 37 5 71.28837734133977\n",
      "little girl 80 27 8 68.66609037830294\n",
      "young hunter 40 14 6 65.60029780468453\n",
      "Audley Court 3 3 3 63.42198886696671\n",
      "could see 96 56 9 61.56793780013763\n",
      "young man 40 154 9 59.46754617578933\n",
      "CHAPTER III 28 4 4 59.29458839273477\n"
     ]
    }
   ],
   "source": [
    "from nltk.collocations import (\n",
    "    BigramCollocationFinder, BigramAssocMeasures,  \n",
    "    TrigramCollocationFinder, TrigramAssocMeasures,  \n",
    "    QuadgramCollocationFinder, QuadgramAssocMeasures\n",
    ")\n",
    "from nltk.corpus import stopwords\n",
    "tokens = [token for token in nltk.word_tokenize(get_book(244).page_content) if token.isalpha()]\n",
    "\n",
    "# choose bi-grams, tri-grams, quad-grams\n",
    "finder = QuadgramCollocationFinder.from_words(tokens)\n",
    "finder = TrigramCollocationFinder.from_words(tokens)\n",
    "finder = BigramCollocationFinder.from_words(tokens)\n",
    "\n",
    "# choose a measure (must match with the finder, here for bi-grams)\n",
    "measure = BigramAssocMeasures.raw_freq\n",
    "measure = BigramAssocMeasures.pmi\n",
    "measure = BigramAssocMeasures.likelihood_ratio\n",
    "\n",
    "\n",
    "# apply frequency filter\n",
    "finder.apply_freq_filter(3)\n",
    "\n",
    "#apply stop word filter\n",
    "ignored_words = stopwords.words('english')\n",
    "stopword_filter = lambda w: len(w) < 3 or w.lower() in ignored_words\n",
    "finder.apply_word_filter(stopword_filter)\n",
    "\n",
    "# obtain results (top-k)\n",
    "k = 20\n",
    "scores = finder.score_ngrams(measure)[:k]\n",
    "\n",
    "# output term 1, term 2, freq of term 1, freq of term 2, freq of bigram, score\n",
    "for ((t1,t2),score) in scores:\n",
    "    print(f'{t1} {t2} {finder.word_fd[t1]} {finder.word_fd[t2]} {finder.ngram_fd[(t1,t2)]} {score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
