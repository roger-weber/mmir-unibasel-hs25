{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run first the [setup notebook](./00-setup.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS and NER tagging of dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Project Gutenberg, 244: A Study in Scarlet (en), Arthur Conan Doyle\n",
    "text_en = \"\"\"\n",
    "This was a lofty chamber, lined and littered with countless bottles.\n",
    "Broad, low tables were scattered about, which bristled with retorts,\n",
    "test-tubes, and little Bunsen lamps, with their blue flickering flames.\n",
    "There was only one student in the room, who was bending over a distant\n",
    "table absorbed in his work. At the sound of our steps he glanced round\n",
    "and sprang to his feet with a cry of pleasure. “I’ve found it! I’ve\n",
    "found it,” he shouted to my companion, running towards us with a\n",
    "test-tube in his hand. “I have found a re-agent which is precipitated\n",
    "by hæmoglobin, and by nothing else.” Had he discovered a gold mine,\n",
    "greater delight could not have shone upon his features.\n",
    "\"\"\".strip()\n",
    "\n",
    "text_en = \"The quick brown fox jumps over the lazy dog.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from transformers import pipeline\n",
    "\n",
    "nlp_bert = pipeline(\"token-classification\", model=\"vblagoje/bert-english-uncased-finetuned-pos\", aggregation_strategy=\"max\")\n",
    "nlp_bertweet = pipeline(\"token-classification\", model=\"TweebankNLP/bertweet-tb2_ewt-pos-tagging\", aggregation_strategy=\"simple\")\n",
    "\n",
    "spacy.prefer_gpu()\n",
    "nlp_spacy = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "def add_tokens(lookup: dict, name: str, tagged_tokens: list[tuple[str,str]]):\n",
    "  for token, tag in tagged_tokens:\n",
    "    token = token.replace('@@','').lower()\n",
    "    if not token.isalpha():\n",
    "      continue\n",
    "    if not token in lookup:\n",
    "      lookup[token] = defaultdict(str)\n",
    "      lookup[token]['token'] = token\n",
    "    lookup[token][name] = tag\n",
    "\n",
    "# tagset = None for standard, or tagset = 'universal'\n",
    "def get_pos_nltk(text: str, tagset: str=None):\n",
    "  tokens = nltk.word_tokenize(text_en)\n",
    "  return nltk.pos_tag(tokens, tagset=tagset)\n",
    "\n",
    "def get_pos_spacy(text: str):\n",
    "  tokens = nlp_spacy(text)\n",
    "  return [(token.text, token.pos_) for token in tokens]\n",
    "\n",
    "def get_pos_bert(text: str):\n",
    "  tokens = nlp_bert(text)\n",
    "  return [(token['word'], token['entity_group']) for token in tokens]\n",
    "\n",
    "def get_pos_bertweet(text: str):\n",
    "  tokens = nlp_bertweet(text)\n",
    "  return [(token['word'], token['entity_group']) for token in tokens]\n",
    "\n",
    "\n",
    "lookup = {}\n",
    "add_tokens(lookup, 'nltk(standard)', get_pos_nltk(text_en))\n",
    "add_tokens(lookup, 'nltk(universal)', get_pos_nltk(text_en, 'universal'))\n",
    "add_tokens(lookup, 'spaCy', get_pos_spacy(text_en))\n",
    "add_tokens(lookup, 'BERT', get_pos_bert(text_en))\n",
    "add_tokens(lookup, 'BERTweet', get_pos_bertweet(text_en))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| term   | nltk (pos)   | nltk (universal)   | spaCy   | BERT   | BERTweet   |\n",
       "|:-------|:-------------|:-------------------|:--------|:-------|:-----------|\n",
       "| the    | DT           | DET                | DET     | DET    | DET        |\n",
       "| quick  | JJ           | ADJ                | ADJ     |        |            |\n",
       "| brown  | NN           | NOUN               | ADJ     |        |            |\n",
       "| fox    | NN           | NOUN               | NOUN    | NOUN   | NOUN       |\n",
       "| jumps  | VBZ          | VERB               | VERB    | VERB   | VERB       |\n",
       "| over   | IN           | ADP                | ADP     | ADP    | ADP        |\n",
       "| lazy   | JJ           | ADJ                | ADJ     | ADJ    | ADJ        |\n",
       "| dog    | NN           | NOUN               | NOUN    | NOUN   | NOUN       |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from tabulate import tabulate\n",
    "\n",
    "headers = ['term', 'nltk (pos)', 'nltk (universal)', 'spaCy', 'BERT', 'BERTweet']\n",
    "rows = []\n",
    "\n",
    "for e in lookup.values():\n",
    "  rows.append([e['token'], e['nltk(standard)'],e['nltk(universal)'],e['spaCy'],e['BERT'],e['BERTweet']])\n",
    "  if len(rows) > 30:\n",
    "    break\n",
    "\n",
    "Markdown(tabulate(rows, headers, tablefmt='pipe'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| tag (nltk)   |   freq |\n",
       "|:-------------|-------:|\n",
       "| NN           |   6906 |\n",
       "| IN           |   5602 |\n",
       "| DT           |   4620 |\n",
       "| PRP          |   4031 |\n",
       "| VBD          |   3459 |\n",
       "| JJ           |   3070 |\n",
       "| ,            |   2959 |\n",
       "| NNP          |   2558 |\n",
       "| .            |   2433 |\n",
       "| RB           |   2171 |\n",
       "| CC           |   1786 |\n",
       "| VB           |   1730 |\n",
       "| NNS          |   1470 |\n",
       "| PRP$         |   1358 |\n",
       "| VBN          |   1233 |\n",
       "| TO           |   1081 |\n",
       "| VBP          |    881 |\n",
       "| VBG          |    709 |\n",
       "| VBZ          |    678 |\n",
       "| MD           |    602 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "| tag (nltk, universal)   |   freq |\n",
       "|:------------------------|-------:|\n",
       "| NOUN                    |  10953 |\n",
       "| VERB                    |   9292 |\n",
       "| PRON                    |   5653 |\n",
       "| ADP                     |   5602 |\n",
       "| .                       |   5550 |\n",
       "| DET                     |   5260 |\n",
       "| ADJ                     |   3234 |\n",
       "| ADV                     |   2520 |\n",
       "| CONJ                    |   1786 |\n",
       "| PRT                     |   1359 |\n",
       "| NUM                     |    345 |\n",
       "| X                       |     49 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "| tag (spaCy)   |   freq |\n",
       "|:--------------|-------:|\n",
       "| PUNCT         |   8086 |\n",
       "| NOUN          |   7467 |\n",
       "| PRON          |   6759 |\n",
       "| VERB          |   6019 |\n",
       "| ADP           |   5074 |\n",
       "| DET           |   4443 |\n",
       "| SPACE         |   3844 |\n",
       "| AUX           |   3064 |\n",
       "| ADJ           |   2854 |\n",
       "| ADV           |   2266 |\n",
       "| CCONJ         |   1702 |\n",
       "| PROPN         |   1609 |\n",
       "| SCONJ         |   1446 |\n",
       "| PART          |    973 |\n",
       "| NUM           |    403 |\n",
       "| INTJ          |     84 |\n",
       "| X             |     16 |\n",
       "| SYM           |      1 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from helpers import get_book\n",
    "from collections import Counter\n",
    "\n",
    "book = get_book(244)\n",
    "\n",
    "tokens = nltk.word_tokenize(book.page_content)\n",
    "tagged_tokens = nltk.pos_tag(tokens)\n",
    "freqs = nltk.FreqDist(tag for (word, tag) in tagged_tokens).most_common(20)\n",
    "display(Markdown(tabulate(freqs, [\"tag (nltk)\", \"freq\"], tablefmt='pipe')))\n",
    "\n",
    "tagged_tokens = nltk.pos_tag(tokens, tagset=\"universal\")\n",
    "freqs = nltk.FreqDist(tag for (word, tag) in tagged_tokens).most_common(20)\n",
    "display(Markdown(tabulate(freqs, [\"tag (nltk, universal)\", \"freq\"], tablefmt='pipe')))\n",
    "\n",
    "tokens = nlp_spacy(book.page_content)\n",
    "freqs = nltk.FreqDist(t.pos_ for t in tokens).most_common(20)\n",
    "display(Markdown(tabulate(freqs, [\"tag (spaCy)\", \"freq\"], tablefmt='pipe')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,1176.0,168.0\" width=\"1176px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"10.2041%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PERSON</text></svg><svg width=\"40%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Jack</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"20%\" y1=\"20px\" y2=\"48px\" /><svg width=\"60%\" x=\"40%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Higgins</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"70%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"5.10204%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.04082%\" x=\"10.2041%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"11.2245%\" y1=\"20px\" y2=\"48px\" /><svg width=\"6.12245%\" x=\"12.2449%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">wearing</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBG</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"15.3061%\" y1=\"20px\" y2=\"48px\" /><svg width=\"5.44218%\" x=\"18.3673%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PERSON</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Nike</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"21.0884%\" y1=\"20px\" y2=\"48px\" /><svg width=\"4.7619%\" x=\"23.8095%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">shoes</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNS</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"26.1905%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.04082%\" x=\"28.5714%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"29.5918%\" y1=\"20px\" y2=\"48px\" /><svg width=\"6.80272%\" x=\"30.6122%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">deposits</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNS</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"34.0136%\" y1=\"20px\" y2=\"48px\" /><svg width=\"6.12245%\" x=\"37.415%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">£50,000</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"40.4762%\" y1=\"20px\" y2=\"48px\" /><svg width=\"4.08163%\" x=\"43.5374%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">with</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"45.5782%\" y1=\"20px\" y2=\"48px\" /><svg width=\"9.52381%\" x=\"47.619%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">ORGANIZATION</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">BestBank</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"52.381%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.72109%\" x=\"57.1429%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">in</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"58.5034%\" y1=\"20px\" y2=\"48px\" /><svg width=\"5.44218%\" x=\"59.8639%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">GPE</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">London</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"62.585%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.72109%\" x=\"65.3061%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">at</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"66.6667%\" y1=\"20px\" y2=\"48px\" /><svg width=\"10.8844%\" x=\"68.0272%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">FACILITY</text></svg><svg width=\"50%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Jermyn</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"20px\" y2=\"48px\" /><svg width=\"50%\" x=\"50%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Street</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"73.4694%\" y1=\"20px\" y2=\"48px\" /><svg width=\"4.7619%\" x=\"78.9116%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">close</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">RB</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"81.2925%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.72109%\" x=\"83.6735%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">to</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">TO</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"85.034%\" y1=\"20px\" y2=\"48px\" /><svg width=\"13.6054%\" x=\"86.3946%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PERSON</text></svg><svg width=\"60%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Piccadilly</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"30%\" y1=\"20px\" y2=\"48px\" /><svg width=\"40%\" x=\"60%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Circus</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"80%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"93.1973%\" y1=\"20px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [Tree('PERSON', [('Jack', 'NNP'), ('Higgins', 'NNP')]), (',', ','), ('wearing', 'VBG'), Tree('PERSON', [('Nike', 'NNP')]), ('shoes', 'NNS'), (',', ','), ('deposits', 'NNS'), ('£50,000', 'VBP'), ('with', 'IN'), Tree('ORGANIZATION', [('BestBank', 'NNP')]), ('in', 'IN'), Tree('GPE', [('London', 'NNP')]), ('at', 'IN'), Tree('FACILITY', [('Jermyn', 'NNP'), ('Street', 'NNP')]), ('close', 'RB'), ('to', 'TO'), Tree('PERSON', [('Piccadilly', 'NNP'), ('Circus', 'NNP')])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_ner = \"Jack Higgins, wearing Nike shoes, deposits £50,000 with BestBank in London at Jermyn Street close to Piccadilly Circus\"\n",
    "nlp_bert = pipeline(\"ner\", model=\"dslim/bert-base-NER\", aggregation_strategy=\"max\")\n",
    "\n",
    "def add_tokens(lookup: dict, name: str, tagged_tokens: list[tuple[str,str]]):\n",
    "  for token, tag in tagged_tokens:\n",
    "    if not token in lookup:\n",
    "      lookup[token] = defaultdict(str)\n",
    "      lookup[token]['token'] = token\n",
    "    lookup[token][name] = tag\n",
    "\n",
    "def get_ner_nltk(text: str):\n",
    "  tokens = nltk.word_tokenize(text)\n",
    "  tagged_tokens = nltk.pos_tag(tokens)\n",
    "  display(nltk.ne_chunk(tagged_tokens))\n",
    "  ner_chunks = [chunk for chunk in nltk.ne_chunk(tagged_tokens) if hasattr(chunk,'label')]\n",
    "  return [(' '.join(c[0] for c in chunk), chunk.label()) for chunk in ner_chunks]\n",
    "\n",
    "def get_ner_spacy(text: str):\n",
    "  tokens = nlp_spacy(text).ents\n",
    "  return [(t.text, t.label_) for t in tokens]\n",
    "\n",
    "def get_ner_bert(text: str):\n",
    "  tokens = nlp_bert(text_ner)\n",
    "  return [(t['word'], t['entity_group']) for t in tokens]\n",
    "\n",
    "lookup = {}\n",
    "add_tokens(lookup, 'nltk', get_ner_nltk(text_ner))\n",
    "add_tokens(lookup, 'spaCy', get_ner_spacy(text_ner))\n",
    "add_tokens(lookup, 'BERT', get_ner_bert(text_ner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| term              | nltk         | spaCy   | BERT   |\n",
       "|:------------------|:-------------|:--------|:-------|\n",
       "| 50,000            |              | MONEY   |        |\n",
       "| BestBank          | ORGANIZATION | ORG     | ORG    |\n",
       "| Jack Higgins      | PERSON       | PERSON  | PER    |\n",
       "| Jermyn Street     | FACILITY     | FAC     | LOC    |\n",
       "| London            | GPE          | GPE     | LOC    |\n",
       "| Nike              | PERSON       | ORG     | MISC   |\n",
       "| Piccadilly Circus | PERSON       | ORG     | LOC    |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = ['term', 'nltk', 'spaCy', 'BERT']\n",
    "rows = []\n",
    "\n",
    "for e in lookup.values():\n",
    "  rows.append([e['token'], e['nltk'],e['spaCy'],e['BERT']])\n",
    "  if len(rows) > 30:\n",
    "    break\n",
    "rows.sort()\n",
    "Markdown(tabulate(rows, headers, tablefmt='pipe'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
