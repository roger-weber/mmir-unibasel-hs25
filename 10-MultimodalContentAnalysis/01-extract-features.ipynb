{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction from images\n",
    "\n",
    "The generative AI part of this notebook requires an AWS account with bedrock models enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet --upgrade pip\n",
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, JSON, clear_output\n",
    "import textwrap\n",
    "import helpers as aws\n",
    "import os, json\n",
    "from tabulate import tabulate\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt \n",
    "from contextlib import contextmanager\n",
    "import textwrap\n",
    "import numpy as np\n",
    "\n",
    "local_images = [f for f in os.listdir('.') if f.endswith('.jpg')]\n",
    "\n",
    "@contextmanager\n",
    "def image_spinner(out):\n",
    "    image = open('spinner.gif', 'rb').read()\n",
    "    with out:\n",
    "        clear_output()\n",
    "        display(widgets.Image(value=image, width=100))\n",
    "        yield\n",
    "        clear_output()\n",
    "\n",
    "\n",
    "def print_wrapped(text, width=80):\n",
    "    for line in textwrap.wrap(text, width):\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_edges(file):\n",
    "    # Load the image\n",
    "    image = cv2.imread(file) \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Display the original image and the edges\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.title('Original Image')\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image)\n",
    "\n",
    "    # display canny edges\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.title('Edges')\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(edges)\n",
    "\n",
    "    # display harris corners\n",
    "    # dst = cv2.cornerHarris(gray, 3, 5, 0.1)\n",
    "    # corners = dst > 0.05 * dst.max()\n",
    "    # coord = np.argwhere(corners)\n",
    "    # img = image.copy()\n",
    "    # for y, x in coord:\n",
    "    #     cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "\n",
    "    # plt.subplot(2, 2, 3)\n",
    "    # plt.title('Harris Corners')\n",
    "    # plt.axis(\"off\")\n",
    "    # plt.imshow(img)\n",
    "\n",
    "    # display color histogram\n",
    "    blue_color = cv2.calcHist([image], [0], None, [256], [0, 256]) \n",
    "    red_color = cv2.calcHist([image], [1], None, [256], [0, 256]) \n",
    "    green_color = cv2.calcHist([image], [2], None, [256], [0, 256]) \n",
    "    gray_scale = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
    "\n",
    "    # Separate Histograms for each color \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.title(\"Color Distribution\") \n",
    "    plt.xlabel(\"Bins\")\n",
    "    plt.ylabel(\"# of Pixels\")\n",
    "    plt.plot(blue_color, color=\"blue\")\n",
    "    plt.plot(green_color, color=\"green\")\n",
    "    plt.plot(red_color, color=\"red\")\n",
    "    plt.plot(gray_scale, color=\"gray\")\n",
    "    plt.xlim([0, 256])\n",
    "\n",
    "    # display sift features\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints = sift.detect(gray, None)\n",
    "    img = cv2.drawKeypoints(image, keypoints, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.title('SIFT Keypoints')\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for file in local_images:\n",
    "    plot_image_edges(file)\n",
    "\n",
    "print(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GenAI based feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = aws.image_prompts.list()\n",
    "\n",
    "out_image = widgets.Output(layout = {'padding': '0px 50px', 'max_width': '400px'})\n",
    "out_text = widgets.Output(layout = {'padding': '0px 50px', 'max_width': '1000px'})\n",
    "\n",
    "opt_image = widgets.Dropdown(description='images', options=local_images, value=None)\n",
    "opt_prompt = widgets.Dropdown(description='prompt', options=prompts, value=None)\n",
    "\n",
    "image = None\n",
    "\n",
    "def on_image_change(*args):\n",
    "    global image\n",
    "    opt_prompt.value = None\n",
    "    out_text.clear_output()\n",
    "    image = open(opt_image.value, 'rb').read()\n",
    "    with out_image:\n",
    "        clear_output()\n",
    "        display(widgets.Image(value=image,width=300))\n",
    "\n",
    "def on_prompt_change(*args):\n",
    "    text = \"\"\n",
    "    if image == None: return\n",
    "    with image_spinner(out_text):\n",
    "        text = aws.create_image_description(image, opt_prompt.value)\n",
    "\n",
    "    with out_text:\n",
    "        clear_output()\n",
    "        if opt_prompt.value == 'json':\n",
    "            display(Markdown(\"```json\\n\"+text+\"\\n```\"))\n",
    "        else:\n",
    "            display(Markdown(text))\n",
    "\n",
    "\n",
    "# observe changes\n",
    "opt_image.observe(on_image_change, 'value')\n",
    "opt_prompt.observe(on_prompt_change, 'value')\n",
    "\n",
    "# display\n",
    "form_data = widgets.GridBox([opt_image, opt_prompt], layout = {'margin': '0px 0px 20px', 'grid_template_columns': 'min-content min-content'})\n",
    "display(widgets.VBox([form_data, widgets.HBox([out_image, out_text])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('federer.jpg') \n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display the original image and the edges\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "image = open('federer.jpg', 'rb').read()\n",
    "text = aws.create_image_description(image, 'json')\n",
    "display(Markdown(\"```json\\n\"+text+\"\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction from audio (speech)\n",
    "\n",
    "To enable the demo, download podcast from [here](https://podcast.datenschutzpartner.ch/273-outsourcing-cloud-behoerden-kanton-zuerich-david-rosenthal) and store it in an S3 bucket. Then update the s3 location for the transcribe job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "mp3_s3_location = 's3://drweb-playground/media/podcast-swissgerman.mp3'\n",
    "aws.s3_download_location(mp3_s3_location)\n",
    "\n",
    "job = aws.TranscribeJob('podcast-swissgerman-2', mp3_s3_location, 'de-CH')\n",
    "job.start()\n",
    "\n",
    "max_count = 300\n",
    "progress = widgets.IntProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=max_count,\n",
    "    step=1,\n",
    "    description='Transcribing:',\n",
    "    bar_style='success',\n",
    "    orientation='horizontal',\n",
    "    layout=widgets.Layout(width='50%')\n",
    ")\n",
    "display(progress)\n",
    "\n",
    "count = 0\n",
    "while count <= max_count:\n",
    "    progress.value = count\n",
    "    if job.is_finished(): \n",
    "        break\n",
    "    time.sleep(1)\n",
    "    count += 1\n",
    "\n",
    "text = job.get_transcript()\n",
    "Markdown(text[:4000]+\"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = aws.get_text_summary(text, 'summarize')\n",
    "Markdown(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words = aws.get_text_summary(text, 'keywords')\n",
    "Markdown(key_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_metadata = aws.get_text_summary(text, 'json')\n",
    "print(json_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
