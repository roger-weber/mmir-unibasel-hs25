{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run first the [setup notebook](./00-setup.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Independence Retrieval (BIR) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import  print_table\n",
    "from probabilistic import BIRRetriever, Feedback, TopKList\n",
    "from datasets import imdb as collection\n",
    "import ipywidgets as widgets\n",
    "import random\n",
    "import math\n",
    "from itertools import islice\n",
    "from typing import Callable\n",
    "from helpers import set_of_words\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|   id | title                           |   year |   runtime |   rating | genre                 | actors                          | summary                                                                                               |\n",
       "|-----:|:--------------------------------|-------:|----------:|---------:|:----------------------|:--------------------------------|:------------------------------------------------------------------------------------------------------|\n",
       "|    1 | The Shawshank Redemption        |   1994 |       142 |      9.3 | Drama                 | Tim Robbins Morgan Freeman Bob… | Two imprisoned men bond over a number of years, finding solace and eventual redemption through acts … |\n",
       "|    2 | The Godfather                   |   1972 |       175 |      9.2 | Crime Drama           | Marlon Brando Al Pacino James … | An organized crime dynasty's aging patriarch transfers control of his clandestine empire to his relu… |\n",
       "|    3 | The Dark Knight                 |   2008 |       152 |      9   | Action Crime Drama    | Christian Bale Heath Ledger Aa… | When the menace known as the Joker wreaks havoc and chaos on the people of Gotham, Batman must accep… |\n",
       "|    4 | The Godfather: Part II          |   1974 |       202 |      9   | Crime Drama           | Al Pacino Robert De Niro Rober… | The early life and career of Vito Corleone in 1920s New York City is portrayed, while his son, Micha… |\n",
       "|    5 | 12 Angry Men                    |   1957 |        96 |      9   | Crime Drama           | Henry Fonda Lee J. Cobb Martin… | A jury holdout attempts to prevent a miscarriage of justice by forcing his colleagues to reconsider … |\n",
       "|    6 | The Lord of the Rings: The Ret… |   2003 |       201 |      8.9 | Action Adventure Dra… | Elijah Wood Viggo Mortensen Ia… | Gandalf and Aragorn lead the World of Men against Sauron's army to draw his gaze from Frodo and Sam … |\n",
       "|    7 | Pulp Fiction                    |   1994 |       154 |      8.9 | Crime Drama           | John Travolta Uma Thurman Samu… | The lives of two mob hitmen, a boxer, a gangster and his wife, and a pair of diner bandits intertwin… |\n",
       "|    8 | Schindler's List                |   1993 |       195 |      8.9 | Biography Drama Hist… | Liam Neeson Ralph Fiennes Ben … | In German-occupied Poland during World War II, industrialist Oskar Schindler gradually becomes conce… |\n",
       "|    9 | Inception                       |   2010 |       148 |      8.8 | Action Adventure Sci… | Leonardo DiCaprio Joseph Gordo… | A thief who steals corporate secrets through the use of dream-sharing technology is given the invers… |\n",
       "|   10 | Fight Club                      |   1999 |       139 |      8.8 | Drama                 | Brad Pitt Edward Norton Meat L… | An insomniac office worker and a devil-may-care soapmaker form an underground fight club that evolve… |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "| term       |   df | posting                                                                             |\n",
       "|:-----------|-----:|:------------------------------------------------------------------------------------|\n",
       "| dark       |   14 | [3, 11, 64, 110, 137, 155, 227, 365, 385, 628, 701, 878, 928, 960]                  |\n",
       "| helps      |    7 | [295, 622, 681, 712, 724, 904, 990]                                                 |\n",
       "| del        |    7 | [97, 214, 250, 541, 894, 939, 958]                                                  |\n",
       "| harry      |   14 | [53, 227, 270, 310, 319, 390, 507, 712, 756, 782, 854, 928, 948, 976]               |\n",
       "| civil      |    9 | [315, 348, 403, 554, 584, 674, 677, 748, 883]                                       |\n",
       "| leigh      |    8 | [50, 315, 439, 448, 549, 585, 779, 933]                                             |\n",
       "| williams   |   17 | [17, 72, 100, 110, 188, 216, 249, 267, 400, 581, 593, 672, 725, 774, 804, 893, 934] |\n",
       "| use        |    7 | [9, 118, 208, 429, 762, 874, 940]                                                   |\n",
       "| successful |    7 | [157, 176, 199, 393, 660, 911, 986]                                                 |\n",
       "| baby       |    9 | [235, 250, 294, 327, 426, 634, 716, 889, 923]                                       |\n",
       "| jeff       |   12 | [67, 253, 263, 422, 503, 682, 742, 817, 836, 890, 897, 905]                         |\n",
       "| violent    |   16 | [54, 97, 112, 134, 201, 258, 365, 449, 520, 550, 606, 703, 719, 919, 954, 959]      |\n",
       "| singer     |   12 | [62, 343, 387, 415, 675, 712, 771, 773, 795, 835, 904, 924]                         |\n",
       "| hopkins    |    6 | [29, 277, 546, 633, 662, 988]                                                       |\n",
       "| destroy    |   10 | [11, 110, 170, 227, 305, 390, 494, 752, 756, 785]                                   |\n",
       "| audrey     |    8 | [96, 447, 548, 701, 704, 871, 937, 996]                                             |\n",
       "| creates    |    6 | [241, 494, 503, 749, 912, 934]                                                      |\n",
       "| gleeson    |    8 | [220, 344, 478, 483, 495, 594, 765, 921]                                            |\n",
       "| reality    |    7 | [222, 251, 448, 498, 516, 589, 656]                                                 |\n",
       "| con        |    7 | [113, 244, 285, 331, 475, 509, 513]                                                 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 documents in collection\n",
      "9836 distinct terms in collection\n",
      "26200 postings\n"
     ]
    }
   ],
   "source": [
    "# load data set and index collection for boolean retrieval\n",
    "retriever = BIRRetriever(collection.load())\n",
    "\n",
    "# show collection\n",
    "n, m = min(10, retriever.n_docs), min(20, retriever.n_terms)\n",
    "\n",
    "print_table([collection.format(doc) for doc in retriever.documents.values()], collection.headers(), max_rows = n)\n",
    "print_table(random.sample([[term, df, retriever.index[term]] for term, df in retriever.vocabulary.items() if df > 5], m), ['term', 'df', 'posting'], max_rows=20)\n",
    "print(f'{retriever.n_docs} documents in collection')\n",
    "print(f'{retriever.n_terms} distinct terms in collection')\n",
    "print('{count} postings'.format(count=sum([len(postings) for postings in retriever.index.values()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations of c_j-weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BIRRetriever(BIRRetriever):\n",
    "    def cj_weight(self, term: str, feedback: Feedback):\n",
    "        doc_freq = len(self.index[term])\n",
    "        if feedback.is_initial_step():\n",
    "            rj = 0.5\n",
    "            nj = (doc_freq + 0.5) / (len(self.documents) + 1)\n",
    "        else:\n",
    "            # get postings as set to simplify calculations in Python\n",
    "            docs = set(self.index[term])\n",
    "\n",
    "            # number of assessed relevant documents which have the term\n",
    "            lj, L = len(feedback.relevant & docs), len(feedback.relevant)\n",
    "            \n",
    "            # number of assessed documents which have the term\n",
    "            kj, K = len(feedback.assessed & docs), len(feedback.assessed)\n",
    "            \n",
    "            # calculate rj and nj\n",
    "            rj = (lj + 0.5) / (L + 1)\n",
    "            nj = (kj - lj + 0.5) / (K - L + 1)\n",
    "            \n",
    "        return math.log(rj / (1 - rj) * (1 - nj) / nj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term & document filtering with options\n",
    "Pruning of terms and documents based on the following settings:\n",
    "- `PRUNE_NEGATIVE_WEIGHTS: bool = False`, set this property to True to remove terms with negative weights\n",
    "- `PRUNE_WEIGHT_THRESHOLD: bool  = False`, set this property to remove terms with absolute weights smaller than this value\n",
    "- `PRUNE_TOPK: bool | int = False`, set this property to select top-k weights based on absolute values\n",
    "- `PRUNE_NON_RELEVANT: bool = False`, set this property to true to prune non-relevant documents from result list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BIRRetriever(BIRRetriever):\n",
    "    # set this property to True to remove terms with negative weights\n",
    "    PRUNE_NEGATIVE_WEIGHTS = False\n",
    "\n",
    "    # set this property to remove terms with absolute weights smaller than this value\n",
    "    PRUNE_WEIGHT_THRESHOLD  = False\n",
    "\n",
    "    # set this property to select top-k weights based on absolute values\n",
    "    PRUNE_TOPK = False\n",
    "\n",
    "    # set this property to true to prune non-relevant documents from result list\n",
    "    PRUNE_NON_RELEVANT = False\n",
    "\n",
    "    def query_weights(self, terms: set[str], feedback: Feedback) -> list[tuple[str,float]]:\n",
    "        # remove terms not in vocabulary\n",
    "        terms = list(filter(lambda t: t in self.vocabulary, terms))\n",
    "\n",
    "        # calculate weigths and produce tuples (term, weight)\n",
    "        term_weights = list(map(lambda t: (t, self.cj_weight(t, feedback)), terms))\n",
    "        \n",
    "        # filter terms with negative weights\n",
    "        if self.PRUNE_NEGATIVE_WEIGHTS:\n",
    "            term_weights = list(filter(lambda t: t[1] >= 0, term_weights))\n",
    "        \n",
    "        # filter terms with small absolute weights\n",
    "        if self.PRUNE_WEIGHT_THRESHOLD:\n",
    "            term_weights = list(filter(lambda t: abs(t[1]) > self.PRUNE_WEIGHT_THRESHOLD, term_weights))\n",
    "        \n",
    "        # select top-k terms based on absolute values\n",
    "        if self.PRUNE_TOPK:\n",
    "            term_weights = sorted(term_weights, key = lambda t: (-abs(t[1]),len(self.index[t[0]]),t[0]))[:self.PRUNE_TOPK]\n",
    "        \n",
    "        return term_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document-at-a-time (DAAT) for BIR Model\n",
    "The implementation of DAAT for the BIR model uses sorted postings and processes postings in ascending order of the document IDs (see Or-implementation of Boolean model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BIRRetriever_DAAT(BIRRetriever):\n",
    "    \"\"\"\n",
    "        Implements the DAAT model for the BIR model using inverted index method.\n",
    "    \"\"\"\n",
    "    def search(self, query: str, k: int, feedback: Feedback, predicate: Callable[[int], bool] = None, selected_docs: set[int] = None) -> TopKList:\n",
    "        query_vector = self._get_vector(query)\n",
    "\n",
    "        # filter terms and obtain c_j-weights for terms in order of their importance \n",
    "        term_weights = self.query_weights(query_vector, feedback)\n",
    "        \n",
    "        # get iterators for each term and fetch first posting\n",
    "        iters = [iter(self.index[term]) for (term, _) in term_weights]\n",
    "        nexts = [next(iter, None) for iter in iters]\n",
    "\n",
    "        # keep track of all retrieved documents and their score; stored as tuples (doc_id, score)\n",
    "        topk = TopKList(k, term_weights, predicate)\n",
    "\n",
    "        # iterate through all streams and calculate score for smallest doc id\n",
    "        while any(e for e in nexts):\n",
    "            # get smallest value from nexts, ignoring None values\n",
    "            smallest = min(nexts, key = lambda x: x or math.inf)\n",
    "\n",
    "            # if we have feedback, make sure document is either relevant or not assessed so far; if we have selected_docs, make sure document is in it\n",
    "            if not(self.PRUNE_NON_RELEVANT and feedback.is_not_relevant(smallest)) and (selected_docs is None or smallest in selected_docs):\n",
    "                # if so, add it to topk\n",
    "                score = sum([term_weights[i][1] for i in range(len(nexts)) if nexts[i] == smallest])\n",
    "                topk.add(smallest, score)\n",
    "            \n",
    "            # for each entry in nexts, fetch next item if entry equals smallest\n",
    "            for i, e in enumerate(nexts):\n",
    "                if e is smallest:\n",
    "                    nexts[i] = next(iters[i], None)\n",
    "        \n",
    "        # finished, return topk for result iteration\n",
    "        return topk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term-at-a-time for BIR \n",
    "This code block defines a class called BIRRetriever_TAAT which implements a Term-At-A-Time (TAAT) approach for Binary Independent Retrieval (BIR) Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BIRRetriever_TAAT(BIRRetriever):\n",
    "    \"\"\"\n",
    "        Implements the TAAT model for the BIR model using inverted index method.\n",
    "    \"\"\"\n",
    "    def search(self, query: str, k: int, feedback: Feedback, predicate: Callable[[int], bool] = None, selected_docs: set[int] = None) -> TopKList:\n",
    "        query_vector = self._get_vector(query)\n",
    "\n",
    "        # filter terms and obtain c_j-weights for terms in order of their importance \n",
    "        term_weights = self.query_weights(query_vector, feedback)\n",
    "        doc_scores = defaultdict(float)\n",
    "\n",
    "        # iterate over terms and fetch postings\n",
    "        for (term, weight) in term_weights:\n",
    "            for doc_id in self.index[term]:\n",
    "                # check if it is either not assessed or relevant; check if doc_id is selected_docs (if given)\n",
    "                if not(self.PRUNE_NON_RELEVANT and feedback.is_not_relevant(doc_id)) and (selected_docs is None or doc_id in selected_docs):\n",
    "                    doc_scores[doc_id] += weight\n",
    "\n",
    "        # we do not need a full sort of doc_scores, but can use the heap in TopKList\n",
    "        topk = TopKList(k, term_weights, predicate)\n",
    "        for doc_id, score in doc_scores.items():\n",
    "            topk.add(doc_id, score)\n",
    "        \n",
    "        # finisheds, return topk for result iteration\n",
    "        return topk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting all together for the movies collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0616d42ed8e4e68a798aa7802934b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(options=('document-at-a-time', 'term-at-a-time'), value='document-at-a-time')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt_strategy = widgets.Dropdown(options=['document-at-a-time', 'term-at-a-time'])\n",
    "display(opt_strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the evaluation strategy\n",
    "if opt_strategy.value == 'document-at-a-time':\n",
    "    retriever = BIRRetriever_DAAT()\n",
    "else:\n",
    "    retriever = BIRRetriever_TAAT()\n",
    "\n",
    "# defines query, predicates, and assessments for demo\n",
    "queries = [\n",
    "    'star wars', \n",
    "    'drama morgan freeman', \n",
    "    'comedy'\n",
    "]\n",
    "assessments = {\n",
    "    'top-100': lambda id: id < 100,\n",
    "    'star in title': lambda id: 'star' in retriever.documents[id]['title'].lower(),\n",
    "    'morgan in actor': lambda id: 'morgan' in retriever.documents[id]['actors'].lower(),\n",
    "    'comedy in genre': lambda id: 'comedy' in retriever.documents[id]['genre'].lower(),\n",
    "}\n",
    "predicates = {\n",
    "    'year < 1990': lambda id: retriever.documents[id]['year'] < 1990,\n",
    "    'year >= 1990': lambda id: retriever.documents[id]['year'] >= 1990,\n",
    "}\n",
    "selections = {\n",
    "    'top-100': list(range(100)),\n",
    "    'top-250': list(range(250)),\n",
    "}\n",
    "\n",
    "# build index\n",
    "retriever.build_index(collection.load())\n",
    "\n",
    "# helper functions\n",
    "def print_feedback(feedback: Feedback, func: str, text: str = 'feedback'):\n",
    "    info = \", \".join([('+' if feedback.is_relevant(doc_id) else '-') + str(doc_id) for doc_id in sorted(feedback.assessed, key=lambda doc_id: (not feedback.is_relevant(doc_id), doc_id))])\n",
    "    print(f'{text} ({func}): {info}')\n",
    "\n",
    "def print_topk(topk: TopKList, feedback: Feedback):\n",
    "    list = []\n",
    "    for entry in topk:\n",
    "        list.append(collection.format(retriever.documents[entry['id']], [\n",
    "            '+' if feedback.is_relevant(entry['id']) else '-' if feedback.is_assessed(entry['id']) else ' ',\n",
    "            entry['rank'],\n",
    "            round(entry['score'], 2)\n",
    "        ]))\n",
    "    print_table(list, collection.headers('rel', 'rank', 'score'), max_rows=len(list))\n",
    "\n",
    "def add_feedback(feedback, topk, n_feedback):\n",
    "    for entry in topk:\n",
    "        if n_feedback <= 0: return\n",
    "        if feedback.is_assessed(entry['id']): continue\n",
    "        feedback.assess(entry['id'])\n",
    "        n_feedback -= 1\n",
    "    for doc_id in filter(lambda doc_id: not feedback.is_assessed(doc_id), retriever.documents.keys()):\n",
    "        if n_feedback <= 0: return\n",
    "        if feedback.is_assessed(doc_id): continue\n",
    "        feedback.assess(doc_id)\n",
    "        n_feedback -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search with feedback iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22080d7481dc4790bdfe6b24378cfd63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description=' start', icon='play', style=ButtonStyle()), Button(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4df4a262fc468a8b4c7d65805c0b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid #eeeeee', border_left='1px solid #eeeeee', border_right='1px sol…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# remove handlers if we re-execute this cell, need to do this before we overwrite function\n",
    "try:\n",
    "    f_query.unobserve(on_start, 'value')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# define globals\n",
    "feedback = Feedback()\n",
    "\n",
    "def run_query(query: str, k: int, assessment: str, predicate: str, selection: str, n_feedback: int):\n",
    "    global topk\n",
    "    feedback.assessment_func = assessments.get(assessment, None)\n",
    "    print_feedback(feedback, assessment)\n",
    "    print()\n",
    "    topk = retriever.search(query, k, feedback=feedback, predicate=predicates.get(predicate, None), selected_docs=selections.get(selection, None))\n",
    "    add_feedback(feedback, topk, n_feedback)\n",
    "    print_topk(topk, feedback)\n",
    "    for term in sorted(topk.weights.keys(), key = lambda term: -topk.weights[term]):\n",
    "        print(term.rjust(16), topk.weights[term])\n",
    "    print_feedback(feedback, assessment, \"\\nnext feedback\")\n",
    "\n",
    "def on_next(btn):\n",
    "    retriever.PRUNE_NEGATIVE_WEIGHTS = opt_neg.value\n",
    "    retriever.PRUNE_WEIGHT_THRESHOLD = opt_small.value and 0.5\n",
    "    retriever.PRUNE_TOPK = opt_topk.value and 10\n",
    "    retriever.PRUNE_NON_RELEVANT = opt_nonrel.value\n",
    "    if opt_expand.value:\n",
    "        query_text = f_query.value + ' ' + ' '.join(reduce(lambda terms, doc_id: terms | retriever.documents[doc_id]['vector'], feedback.relevant, set()))\n",
    "    else:\n",
    "        query_text = f_query.value\n",
    "    with out:\n",
    "        clear_output()\n",
    "        print(query_text)\n",
    "        run_query(query_text, 20, f_assessment.value, f_predicate.value, f_selection.value, f_feedback.value)\n",
    "\n",
    "def on_start(btn):\n",
    "    feedback.clear()\n",
    "    on_next(btn)\n",
    "\n",
    "# buttons\n",
    "btn_start = widgets.Button(description=' start', icon='play')\n",
    "btn_start.on_click(on_start)\n",
    "btn_next = widgets.Button(description=' next', icon='step-forward')\n",
    "btn_next.on_click(on_next)\n",
    "buttons = widgets.HBox([btn_start, btn_next])\n",
    "\n",
    "# query left side\n",
    "f_query = widgets.Dropdown(description='query',options=list(queries))\n",
    "f_assessment = widgets.Dropdown(description='assessment',options=['<none>'] + list(assessments.keys()))\n",
    "f_feedback = widgets.IntSlider(description='feedback', min=5, max=50, step=5, value=5)\n",
    "f_predicate = widgets.Dropdown(description='predicate',options=['<none>'] + list(predicates.keys()))\n",
    "f_selection = widgets.Dropdown(description='selection',options=['<none>'] + list(selections.keys()))\n",
    "left = widgets.VBox([f_query, f_assessment, f_feedback, f_predicate, f_selection])\n",
    "f_query.observe(on_start, 'value')\n",
    "\n",
    "# options right side\n",
    "opt_neg = widgets.Checkbox(value=False, description='prune negative weights')\n",
    "opt_small = widgets.Checkbox(value=False, description='prune small weights (abs < 0.5)')\n",
    "opt_topk = widgets.Checkbox(value=False, description='keep top 10 weights')\n",
    "opt_nonrel = widgets.Checkbox(value=False, description='prune non relevant documents')\n",
    "opt_expand = widgets.Checkbox(value=False, description='expand query with feedback')\n",
    "right = widgets.VBox([opt_neg, opt_small, opt_topk, opt_nonrel, opt_expand])\n",
    "\n",
    "# display the dialog object\n",
    "display(widgets.VBox([buttons, widgets.HBox([left, right], layout={'margin': '20px'})]))\n",
    "\n",
    "# capture output with this widget\n",
    "out = widgets.Output(layout={'border': '1px solid #eeeeee', 'height': '800px', 'overflow': 'auto', 'padding': '0px 0px 0px 10px'})\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
