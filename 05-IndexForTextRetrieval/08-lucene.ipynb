{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes: this Java notebook requires Ganymede \n",
    "* Ganymede (Java kernel for Jupyter): [Installation and documentation](https://github.com/allen-ball/ganymede)\n",
    "* We need additional libraries for lucene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pom\n",
    "dependencies:\n",
    "- org.apache.lucene:lucene-core:9.7.0\n",
    "- org.apache.lucene:lucene-analysis-common:9.7.0\n",
    "- org.apache.lucene:lucene-queryparser:9.7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common imports (java)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.io.BufferedReader;\n",
    "import java.io.FileReader;\n",
    "import java.io.IOException;\n",
    "import java.io.StringReader;\n",
    "import java.nio.file.Files;\n",
    "import java.nio.file.Paths;\n",
    "\n",
    "import java.util.Arrays;\n",
    "import java.util.ArrayList;\n",
    "import java.util.HashMap;\n",
    "import java.util.Map;\n",
    "import java.util.List;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common imports (lucene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.lucene.analysis.Analyzer;\n",
    "import org.apache.lucene.analysis.CharArraySet;\n",
    "import org.apache.lucene.analysis.FilteringTokenFilter;\n",
    "import org.apache.lucene.analysis.TokenStream;\n",
    "import org.apache.lucene.analysis.Tokenizer;\n",
    "import org.apache.lucene.analysis.en.EnglishAnalyzer;\n",
    "import org.apache.lucene.analysis.en.EnglishPossessiveFilter;\n",
    "import org.apache.lucene.analysis.en.KStemFilter;\n",
    "import org.apache.lucene.analysis.en.PorterStemFilter;\n",
    "import org.apache.lucene.analysis.standard.StandardAnalyzer;\n",
    "import org.apache.lucene.analysis.standard.StandardTokenizer;\n",
    "import org.apache.lucene.analysis.core.LowerCaseFilter;\n",
    "import org.apache.lucene.analysis.miscellaneous.ASCIIFoldingFilter;\n",
    "import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;\n",
    "import org.apache.lucene.document.Document;\n",
    "import org.apache.lucene.document.Field;\n",
    "import org.apache.lucene.document.Field.Store;\n",
    "import org.apache.lucene.document.TextField;\n",
    "import org.apache.lucene.document.IntField;\n",
    "import org.apache.lucene.document.FieldType;\n",
    "import org.apache.lucene.document.FloatField;\n",
    "import org.apache.lucene.document.FloatPoint;\n",
    "import org.apache.lucene.index.DirectoryReader;\n",
    "import org.apache.lucene.index.Fields;\n",
    "import org.apache.lucene.index.IndexOptions;\n",
    "import org.apache.lucene.index.IndexReader;\n",
    "import org.apache.lucene.index.IndexWriter;\n",
    "import org.apache.lucene.index.IndexWriterConfig;\n",
    "import org.apache.lucene.index.LogDocMergePolicy;\n",
    "import org.apache.lucene.index.MergePolicy;\n",
    "import org.apache.lucene.index.MultiTerms;\n",
    "import org.apache.lucene.index.NoMergePolicy;\n",
    "import org.apache.lucene.index.PostingsEnum;\n",
    "import org.apache.lucene.index.StoredFields;\n",
    "import org.apache.lucene.index.Term;\n",
    "import org.apache.lucene.index.Terms;\n",
    "import org.apache.lucene.index.TermsEnum;\n",
    "import org.apache.lucene.index.TermVectors;\n",
    "import org.apache.lucene.search.BooleanQuery;\n",
    "import org.apache.lucene.search.BooleanClause;\n",
    "import org.apache.lucene.search.BooleanClause.Occur;\n",
    "import org.apache.lucene.search.BoostQuery;\n",
    "import org.apache.lucene.search.IndexSearcher;\n",
    "import org.apache.lucene.search.Query;\n",
    "import org.apache.lucene.search.ScoreDoc;\n",
    "import org.apache.lucene.search.TermRangeQuery;\n",
    "import org.apache.lucene.search.TermQuery;\n",
    "import org.apache.lucene.search.TopDocs;\n",
    "import org.apache.lucene.store.Directory;\n",
    "import org.apache.lucene.store.FSDirectory;\n",
    "import org.apache.lucene.store.Directory;\n",
    "import org.apache.lucene.store.FSDirectory;\n",
    "import org.apache.lucene.queryparser.classic.MultiFieldQueryParser;\n",
    "import org.apache.lucene.queryparser.classic.QueryParser;\n",
    "import org.apache.lucene.queryparser.classic.ParseException;\n",
    "import org.apache.lucene.util.BytesRef;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define paths to documents and index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "var fileImdbDataset = \"datasets/imdb_top_1000.csv\";\n",
    "var pathIndex = \"lucene/index\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's read in the data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1000 documents from datasets/imdb_top_1000.csv\n",
      "\n",
      "first document:\n",
      "   summary: Mathilda, a 12-year-old girl, is reluctantly taken in by Léon, a professional assassin, after her family is murdered. An unusual relationship forms as she becomes his protégée and learns the assassin's trade.\n",
      "    actors: Jean Reno Gary Oldman Natalie Portman Danny Aiello\n",
      "      year: 1994\n",
      "     genre: \"Action Crime Drama\"\n",
      "    rating: 8.5\n",
      "   runtime: 110\n",
      "     title: Leon\n"
     ]
    }
   ],
   "source": [
    "List<Map<String, String>> readCollection(String name) throws IOException {\n",
    "    List<Map<String, String>> docs = new ArrayList<Map<String, String>>();\n",
    "    String splitter = \",(?=(?:[^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\";\n",
    "    BufferedReader reader = new BufferedReader(new FileReader(name));\n",
    "    String line, keys[] = reader.readLine().split(splitter);\n",
    "\n",
    "    while ((line = reader.readLine()) != null) {\n",
    "        String[] values = line.split(splitter);\n",
    "        Map<String, String> dataMap = new HashMap<>();\n",
    "\n",
    "        for (int i = 0; i < keys.length; i++) {\n",
    "            // dataMap.put(keys[i], values[i]);\n",
    "            switch (keys[i]) {\n",
    "                case \"Series_Title\":\n",
    "                    dataMap.put(\"title\", values[i]);\n",
    "                    break;\n",
    "                case \"Released_Year\":\n",
    "                    dataMap.put(\"year\", values[i]);\n",
    "                    break;\n",
    "                case \"Runtime\":\n",
    "                    dataMap.put(\"runtime\", values[i].replace(\" min\", \"\"));\n",
    "                    break;\n",
    "                case \"Genre\":\n",
    "                    dataMap.put(\"genre\", values[i].replace(\",\", \"\"));\n",
    "                    break;\n",
    "                case \"IMDB_Rating\":\n",
    "                    dataMap.put(\"rating\", values[i]);\n",
    "                    break;\n",
    "                case \"Overview\":\n",
    "                    dataMap.put(\"summary\", values[i].replace(\"\\\"\", \"\"));\n",
    "                    break;\n",
    "                case \"Star1\":\n",
    "                    dataMap.put(\"actors\", values[i]);\n",
    "                    break;\n",
    "                case \"Star2\":\n",
    "                case \"Star3\":\n",
    "                case \"Star4\":\n",
    "                    dataMap.put(\"actors\", dataMap.get(\"actors\") + \" \" + values[i]);\n",
    "                    break;\n",
    "            }\n",
    "        }\n",
    "        docs.add(dataMap);\n",
    "    }\n",
    "    reader.close();\n",
    "\n",
    "    // print summary\n",
    "    System.out.println(\"Read \" + docs.size() + \" documents from \" + name);\n",
    "    return docs;\n",
    "}\n",
    "\n",
    "var collection = readCollection(fileImdbDataset);\n",
    "System.out.println(\"\\nfirst document:\");\n",
    "collection.get(42).forEach((key, value) -> System.out.println(String.format(\"%10s: %s\", key, value)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzer of Lucene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             text: I think text's values' color goes here; WHAT happens with L�on? do we see IT again; I went there to be gone with houses\n",
      "\n",
      "         standard: i, think, text's, values, color, goes, here, what, happens, with, l�on, do, we, see, it, again, i, went, there, to, be, gone, with, houses, \n",
      "          english: i, think, text, valu, color, goe, here, what, happen, l�on, do, we, see, again, i, went, gone, hous, \n",
      "english/stopwords: think, text, valu, color, goe, here, what, happen, with, l�on, we, see, it, again, went, there, to, be, gone, with, hous, \n",
      "english/folding: i, think, text's, values, color, goes, here, what, happens, with, leon, do, we, see, it, again, i, went, there, to, be, gone, with, houses, \n",
      "      my analyzer: think, text, value, color, go, here, WHAT, happen, with, L�on, again, went, there, gone, with, house, \n",
      "\n",
      "english stopword list:\n",
      "[but, be, with, such, then, for, no, will, not, are, and, their, if, this, on, into, a, or, there, in, that, they, was, is, it, an, the, as, at, these, by, to, of]\n"
     ]
    }
   ],
   "source": [
    "void print_tokens(Analyzer analyzer, String text) throws IOException {\n",
    "    TokenStream ts = analyzer.tokenStream(\"text\", new StringReader(text));\n",
    "    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n",
    "\n",
    "    for(ts.reset(); ts.incrementToken();) \n",
    "        System.out.print(termAtt.toString() + \", \");\n",
    "    ts.end();\n",
    "    System.out.println();\n",
    "}\n",
    "\n",
    "class EnglishASCIIFoldedAnalyzer extends Analyzer {\n",
    "    @Override\n",
    "    protected TokenStreamComponents createComponents(String fieldName) {\n",
    "        Tokenizer tokenizer = new StandardTokenizer();\n",
    "        TokenStream tokenStream = new LowerCaseFilter(tokenizer);\n",
    "        tokenStream = new ASCIIFoldingFilter(tokenStream);\n",
    "        return new TokenStreamComponents(tokenizer, tokenStream);\n",
    "    }\n",
    "}\n",
    "\n",
    "class MyAnalyzer extends Analyzer {\n",
    "    @Override\n",
    "    protected TokenStreamComponents createComponents(String fieldName) {\n",
    "          final Tokenizer source = new StandardTokenizer();\n",
    "          TokenStream tokenStream = new EnglishPossessiveFilter(source);\n",
    "          // tokenStream = new LowerCaseFilter(tokenStream);\n",
    "          tokenStream = new FilteringTokenFilter(tokenStream) {\n",
    "              private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n",
    "              @Override\n",
    "              protected boolean accept() throws IOException {\n",
    "                  return termAtt.length() > 3;\n",
    "              }\n",
    "          };\n",
    "          tokenStream = new KStemFilter(tokenStream);\n",
    "          return new TokenStreamComponents(source, tokenStream);\n",
    "    }\n",
    "}\n",
    "\n",
    "var text = \"I think text's values' color goes here; WHAT happens with Léon? do we see IT again; I went there to be gone with houses\";\n",
    "var stopWords = new CharArraySet(Arrays.asList(\"i\", \"do\"), false);\n",
    "\n",
    "System.out.println(\"             text: \"+ text);\n",
    "System.out.println();\n",
    "\n",
    "// standard analyzer\n",
    "System.out.print(\"         standard: \");\n",
    "print_tokens(new StandardAnalyzer(), text);\n",
    "\n",
    "// english analyzer (with porter stemmer)\n",
    "System.out.print(\"          english: \");\n",
    "print_tokens(new EnglishAnalyzer(), text);\n",
    "\n",
    "// english analyzer (with porter stemmer) and new set of stopwords\n",
    "System.out.print(\"english/stopwords: \");\n",
    "print_tokens(new EnglishAnalyzer(stopWords), text);\n",
    "\n",
    "// english analyzer with ascii folding\n",
    "System.out.print(\"english/folding: \");\n",
    "print_tokens(new EnglishASCIIFoldedAnalyzer(), text);\n",
    "\n",
    "// a custom analyzer, no lower case and kstemmer\n",
    "System.out.print(\"      my analyzer: \");\n",
    "print_tokens(new MyAnalyzer(), text);\n",
    "\n",
    "// print standard stop word list\n",
    "System.out.println(\"\\nenglish stopword list:\");\n",
    "System.out.println(EnglishAnalyzer.getDefaultStopSet());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an index with Lucene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Providing default analyzer, diretory, and index writer/searcher\n",
    "We pick the English Analyzer. Make sure that you always use the *same* analyzer for indexing and searching. Lucene is not checking for this and your search performance can suffer. The directory is on the file system. Using standard configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Analyzer getAnalyzer() {\n",
    "    return new EnglishAnalyzer();\n",
    "}\n",
    "\n",
    "Directory getDirectory() throws IOException {\n",
    "    return FSDirectory.open(Paths.get(pathIndex));\n",
    "}\n",
    "\n",
    "IndexWriter getIndexWriter() throws IOException {\n",
    "    Directory directory = getDirectory();\n",
    "    IndexWriterConfig config = new IndexWriterConfig(getAnalyzer());\n",
    "    return new IndexWriter(directory, config);\n",
    "}\n",
    "\n",
    "IndexWriter getIndexWriter(boolean mergePolicy) throws IOException {\n",
    "    Directory directory = getDirectory();\n",
    "    IndexWriterConfig config = new IndexWriterConfig(getAnalyzer());\n",
    "    MergePolicy policy = mergePolicy ? new LogDocMergePolicy() : NoMergePolicy.INSTANCE;\n",
    "    if (mergePolicy) policy.setNoCFSRatio(1.0);\n",
    "    config.setMergePolicy(policy);\n",
    "    return new IndexWriter(directory, config);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We delete the index first, to load all documents into a fresh index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "void deleteIndex() throws IOException {\n",
    "    IndexWriter writer = getIndexWriter();\n",
    "    writer.deleteAll();\n",
    "    writer.commit();\n",
    "    writer.close();\n",
    "}\n",
    "\n",
    "deleteIndex();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lucene accepts documents with fields\n",
    "`Field.Store.YES` stores the value of the field in the index. That mean when we print results, we have these attributes available form the Lucene index. On the other hand, `Field.Store.NO` does not dtore the values in the index. In our example below, we have to retrieve actors, genre, and summary from the original data file as they are not stored in the Lucene index. \n",
    "\n",
    "The field type decides whether its value is tokenized and available for full-text search:\n",
    "* `TextField`: Reader or String indexed for full-text search\n",
    "* `StringField`: String indexed verbatim as a single token\n",
    "* `IntField`: int indexed for exact/range queries. \n",
    "* `IntPoint`: faster int indexed for exact/range queries. If you need to store the value, also use a `StoredField` \n",
    "* `FloatField`: float indexed for exact/range queries.\n",
    "* `FloatPoint`: faster float indexed for exact/range queries. If you need to store the value, also use a `StoredField` \n",
    "* `StoredField`: Stored-only value for retrieving in summary results\n",
    "\n",
    "In summary, a field can be 'stored' / 'not stored' in the index, and the contents of a field can be used for full-text search, exact/range queries, or not at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Document createDocument(Map<String, String> data) {\n",
    "    Document doc = new Document();\n",
    "\n",
    "    // we store everything we need for result presentation\n",
    "    doc.add(new TextField(\"title\", data.get(\"title\"), Store.YES));\n",
    "    doc.add(new TextField(\"year\", data.get(\"year\"), Store.YES));\n",
    "//    doc.add(new IntField(\"year\", Integer.parseInt(data.get(\"year\")), Store.YES));\n",
    "    doc.add(new IntField(\"runtime\", Integer.parseInt(data.get(\"runtime\")), Store.YES));\n",
    "    doc.add(new FloatField(\"rating\", Float.parseFloat(data.get(\"rating\")), Store.YES));\n",
    "\n",
    "    // we do not store these fields and can't print them in the results\n",
    "    doc.add(new TextField(\"actors\", data.get(\"actors\"), Store.NO));\n",
    "    doc.add(new TextField(\"genre\", data.get(\"genre\"), Store.NO));\n",
    "\n",
    "    // lastly, we use a custom field to show the term vectors in summary\n",
    "    FieldType ftSummary = new FieldType();\n",
    "    ftSummary.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);\n",
    "    ftSummary.setStoreTermVectors(true);\n",
    "    ftSummary.setStoreTermVectorPositions(true);\n",
    "    ftSummary.setTokenized(true);\n",
    "    ftSummary.setStored(true);\n",
    "    doc.add(new Field(\"summary\", data.get(\"summary\"), ftSummary));\n",
    "\n",
    "    return doc;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the index in batches to observe how segment creation works\n",
    "Change the `batchSize` argument in the call to `loadImdbData` and observe the index folder at `./lucene/index`. Every time we create a new `IndexWriter`, Lucene creates a new segment and all documents added with the same index writer are kept in the same segments. \n",
    "\n",
    "Note: we deliberately turn off the merge policy to demonstrate sgements. Do not do in production!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1000 documents from datasets/imdb_top_1000.csv\n"
     ]
    }
   ],
   "source": [
    "void loadBatch(List<Map<String, String>> docs) throws IOException {\n",
    "    IndexWriter writer = null;\n",
    "\n",
    "    try {\n",
    "        writer = getIndexWriter(false);\n",
    "        for (Map<String, String> doc : docs)\n",
    "            writer.addDocument(createDocument(doc));\n",
    "    } finally {\n",
    "        if (writer!=null) writer.close();\n",
    "    }\n",
    "}\n",
    "\n",
    "void loadImdbData(int batchSize) throws IOException {\n",
    "    List<Map<String, String>> collection = readCollection(fileImdbDataset);\n",
    "\n",
    "    deleteIndex();\n",
    "    // load collection in batches to show how segments work\n",
    "    for (int i = 0; i < collection.size(); i += batchSize)\n",
    "        loadBatch(collection.subList(i, Math.min(i + batchSize, collection.size())));\n",
    "}\n",
    "\n",
    "loadImdbData(100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging segments\n",
    "We can force Lucene to merge segments (normally, this is done less costly by the MergePolicy). Above we created 10 segments and you can observe 10 groups (compounded file format) of files in the index folder. Next, we turn on merge policy and force Lucene to produce a compact index with one segment only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "var writer = getIndexWriter(true);\n",
    "writer.forceMerge(1);\n",
    "writer.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Documents in the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc 0: Document<stored,indexed,tokenized<title:The Shawshank Redemption> stored,indexed,tokenized<year:1994> stored<runtime:142> stored<rating:9.3> stored,indexed,tokenized,termVector<summary:Two imprisoned men bond over a number of years, finding solace and eventual redemption through acts of common decency.>>\n",
      "Doc 1: Document<stored,indexed,tokenized<title:The Godfather> stored,indexed,tokenized<year:1972> stored<runtime:175> stored<rating:9.2> stored,indexed,tokenized,termVector<summary:An organized crime dynasty's aging patriarch transfers control of his clandestine empire to his reluctant son.>>\n",
      "Doc 2: Document<stored,indexed,tokenized<title:The Dark Knight> stored,indexed,tokenized<year:2008> stored<runtime:152> stored<rating:9.0> stored,indexed,tokenized,termVector<summary:When the menace known as the Joker wreaks havoc and chaos on the people of Gotham, Batman must accept one of the greatest psychological and physical tests of his ability to fight injustice.>>\n",
      "Doc 3: Document<stored,indexed,tokenized<title:The Godfather: Part II> stored,indexed,tokenized<year:1974> stored<runtime:202> stored<rating:9.0> stored,indexed,tokenized,termVector<summary:The early life and career of Vito Corleone in 1920s New York City is portrayed, while his son, Michael, expands and tightens his grip on the family crime syndicate.>>\n",
      "Doc 4: Document<stored,indexed,tokenized<title:12 Angry Men> stored,indexed,tokenized<year:1957> stored<runtime:96> stored<rating:9.0> stored,indexed,tokenized,termVector<summary:A jury holdout attempts to prevent a miscarriage of justice by forcing his colleagues to reconsider the evidence.>>\n",
      "Doc 5: Document<stored,indexed,tokenized<title:The Lord of the Rings: The Return of the King> stored,indexed,tokenized<year:2003> stored<runtime:201> stored<rating:8.9> stored,indexed,tokenized,termVector<summary:Gandalf and Aragorn lead the World of Men against Sauron's army to draw his gaze from Frodo and Sam as they approach Mount Doom with the One Ring.>>\n",
      "Doc 6: Document<stored,indexed,tokenized<title:Pulp Fiction> stored,indexed,tokenized<year:1994> stored<runtime:154> stored<rating:8.9> stored,indexed,tokenized,termVector<summary:The lives of two mob hitmen, a boxer, a gangster and his wife, and a pair of diner bandits intertwine in four tales of violence and redemption.>>\n",
      "Doc 7: Document<stored,indexed,tokenized<title:Schindler's List> stored,indexed,tokenized<year:1993> stored<runtime:195> stored<rating:8.9> stored,indexed,tokenized,termVector<summary:In German-occupied Poland during World War II, industrialist Oskar Schindler gradually becomes concerned for his Jewish workforce after witnessing their persecution by the Nazis.>>\n",
      "Doc 8: Document<stored,indexed,tokenized<title:Inception> stored,indexed,tokenized<year:2010> stored<runtime:148> stored<rating:8.8> stored,indexed,tokenized,termVector<summary:A thief who steals corporate secrets through the use of dream-sharing technology is given the inverse task of planting an idea into the mind of a C.E.O.>>\n",
      "Doc 9: Document<stored,indexed,tokenized<title:Fight Club> stored,indexed,tokenized<year:1999> stored<runtime:139> stored<rating:8.8> stored,indexed,tokenized,termVector<summary:An insomniac office worker and a devil-may-care soapmaker form an underground fight club that evolves into something much, much more.>>\n"
     ]
    }
   ],
   "source": [
    "void printDocuments(int num) throws IOException {\n",
    "    IndexReader reader = DirectoryReader.open(getDirectory());\n",
    "    StoredFields storedFields = reader.storedFields();\n",
    "    for(int i = 0; i < num; i++) {\n",
    "        Document doc = storedFields.document(i);\n",
    "        System.out.println(\"Doc \" + i + \": \" + doc.toString());\n",
    "    }\n",
    "}\n",
    "\n",
    "printDocuments(10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Terms used in a document\n",
    "This next code is only possible if we store the term vectors (aka document vectors) in the index. We have created a custom field for summary to demonstrate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "summary of doc 42: Mathilda, a 12-year-old girl, is reluctantly taken in by Léon, a professional assassin, after her family is murdered. An unusual relationship forms as she becomes his protégée and learns the assassin's trade.\n",
      "\n",
      "index of doc 42: \n",
      "term             tf   postings\n",
      "12                1   2\n",
      "after             1   17\n",
      "assassin          2   16 38\n",
      "becom             1   28\n",
      "e                 1   34\n",
      "famili            1   19\n",
      "form              1   25\n",
      "girl              1   5\n",
      "g�                1   32\n",
      "her               1   18\n",
      "hi                1   29\n",
      "learn             1   36\n",
      "l�                1   11\n",
      "mathilda          1   0\n",
      "murder            1   21\n",
      "old               1   4\n",
      "profession        1   15\n",
      "prot�             1   30\n",
      "relationship      1   24\n",
      "reluctantli       1   7\n",
      "she               1   27\n",
      "taken             1   8\n",
      "trade             1   39\n",
      "unusu             1   23\n",
      "year              1   3\n",
      "�                 3   12 31 33\n"
     ]
    }
   ],
   "source": [
    "void printDocumentVector(int docNo, String field) throws IOException {\n",
    "    IndexReader reader = DirectoryReader.open(getDirectory());\n",
    "    TermVectors vectors = reader.termVectors();\n",
    "    Terms terms = vectors.get(docNo, field);\n",
    "        \n",
    "    // iterate through terms\n",
    "    System.out.println(\"index of doc \" + docNo + \": \\nterm             tf   postings\");\n",
    "    TermsEnum termsEnum = terms.iterator();\n",
    "    PostingsEnum positions = null;\n",
    "    BytesRef term = null;\n",
    "    while((term = termsEnum.next()) != null) {\n",
    "        String termstr = term.utf8ToString(); // Get the text string of the term.\n",
    "        long freq = termsEnum.totalTermFreq(); // Get the frequency of the term in the document.\n",
    "        \n",
    "        System.out.printf(\"%-12s %6d  \", termstr, freq );\n",
    "        positions = termsEnum.postings(positions, PostingsEnum.POSITIONS );\n",
    "        positions.nextDoc(); // you still need to move the cursor\n",
    "        for(int i = 0; i < freq; i++ )\n",
    "            System.out.print(\" \" + positions.nextPosition());\n",
    "        System.out.println();\n",
    "    }\n",
    "    reader.close();\n",
    "}\n",
    "\n",
    "// print document (to see what happened to it)\n",
    "var docNo = 42;\n",
    "System.out.println(\"\\nsummary of doc \" + docNo + \": \" + collection.get(docNo).get(\"summary\") + \"\\n\");\n",
    "printDocumentVector(docNo, \"summary\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How does the Vocabulary look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 1000\n",
      "    Total terms: 4471\n",
      "  Total sum(tf): 17405\n",
      "     Average tf: 1.04\n",
      "Average doc len: 17.41\n",
      "     Average df: 3.89\n",
      "\n",
      "term             df  sum(tf)\n",
      "hi              375      516\n",
      "who             158      165\n",
      "from            139      148\n",
      "he              138      155\n",
      "young           127      132\n",
      "her             124      164\n",
      "man             116      120\n",
      "after           112      112\n",
      "find            103      106\n",
      "life            103      111\n",
      "when            103      107\n",
      "two              98      104\n",
      "world            82       85\n",
      "becom            73       76\n",
      "year             73       78\n",
      "new              70       75\n",
      "famili           68       71\n",
      "stori            68       68\n",
      "war              68       71\n",
      "up               67       67\n"
     ]
    }
   ],
   "source": [
    "void printVocabulary(String field) throws IOException {\n",
    "    IndexReader reader = DirectoryReader.open(getDirectory());\n",
    "    Terms vocabulary = MultiTerms.getTerms(reader, field);\n",
    "    TermsEnum termsEnum = vocabulary.iterator();\n",
    "    BytesRef term = null;\n",
    "    Object output[][] = new Object[(int)vocabulary.size()][];\n",
    "    int i = 0;\n",
    "\n",
    "    // get all terms from vocbulary and produce the result\n",
    "    while ((term = termsEnum.next()) != null) {\n",
    "        // create an array list with the terms and their frequencies\n",
    "        Object[] list = new Object[]{term.utf8ToString(),termsEnum.docFreq(), termsEnum.totalTermFreq()};\n",
    "        output[i++] = list;\n",
    "    }\n",
    "\n",
    "    // print summary\n",
    "    System.out.println(String.format(\"Total documents: %d\", reader.numDocs()));\n",
    "    System.out.println(String.format(\"    Total terms: %d\", vocabulary.size()));\n",
    "\n",
    "    System.out.println(String.format(\"  Total sum(tf): %d\", reader.getSumTotalTermFreq(field)));\n",
    "    System.out.println(String.format(\"     Average tf: %1.2f\", (float)reader.getSumTotalTermFreq(field)/reader.getSumDocFreq(field)));\n",
    "    System.out.println(String.format(\"Average doc len: %1.2f\", (float)reader.getSumTotalTermFreq(field)/reader.numDocs()));\n",
    "    \n",
    "    System.out.println(String.format(\"     Average df: %1.2f\", (float)reader.getSumTotalTermFreq(field)/vocabulary.size()));\n",
    "    System.out.println(\"\\nterm             df  sum(tf)\");\n",
    "\n",
    "    // show the objects with higest df\n",
    "    Arrays.sort(output, (o1, o2) -> ((Integer)o2[1]).compareTo((Integer)o1[1]));\n",
    "    for (i=0; i<20; i++)\n",
    "        System.out.println(String.format(\"%-12s %6d %8d\", output[i][0], output[i][1], output[i][2]));\n",
    "    reader.close();\n",
    "}\n",
    "\n",
    "printVocabulary(\"summary\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 1000\n",
      "    Total terms: 1624\n",
      "  Total sum(tf): 2298\n",
      "     Average tf: 1.01\n",
      "Average doc len: 2.30\n",
      "     Average df: 1.42\n",
      "\n",
      "term             df  sum(tf)\n",
      "la               23       24\n",
      "man              20       20\n",
      "de               18       18\n",
      "le               18       19\n",
      "2                14       14\n",
      "dai              14       14\n",
      "stori            10       10\n",
      "star              9        9\n",
      "harri             8        8\n",
      "night             8        8\n",
      "war               8        8\n",
      "babi              7        7\n",
      "dark              7        7\n",
      "dead              7        7\n",
      "king              7        7\n",
      "�                 7        7\n",
      "last              6        6\n",
      "men               6        6\n",
      "onc               6        6\n",
      "potter            6        6\n"
     ]
    }
   ],
   "source": [
    "printVocabulary(\"title\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching with Lucene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need an index searcher and query parser with the same settings as for index writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "IndexSearcher getIndexSearcher() throws IOException {\n",
    "    return new IndexSearcher(DirectoryReader.open(getDirectory()));\n",
    "}\n",
    "\n",
    "QueryParser getQueryParser() throws IOException {\n",
    "    return new MultiFieldQueryParser(new String[]{\"title\", \"summary\", \"genre\", \"actors\"}, getAnalyzer());\n",
    "}\n",
    "\n",
    "QueryParser getQueryParser(String field) throws IOException {\n",
    "    return new QueryParser(field, getAnalyzer());\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function takes a query parser and runs a set of queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "void printResults(String query, TopDocs results) throws IOException {\n",
    "    int rank = 1;\n",
    "    System.out.println(\"Query: \" + query);\n",
    "    System.out.printf(\"%3s %5s %6s %6s %7s %6s   %s\\n\", \"#\", \"id\", \"Score\", \"Year\", \"Runtime\", \"Rating\", \"Title\" );\n",
    "    for(ScoreDoc doc: results.scoreDocs) {\n",
    "        Document document = getIndexSearcher().doc(doc.doc);\n",
    "        System.out.printf(\"%3d %5d %6.2f %6s %7s %6s   %s\\n\", rank++, doc.doc, doc.score, \n",
    "            document.get(\"year\"), document.get(\"runtime\"), document.get(\"rating\"), document.get(\"title\") );\n",
    "    } \n",
    "    System.out.println();\n",
    "}\n",
    "\n",
    "void searchExamples(QueryParser parser, String[] queries) throws IOException, ParseException {\n",
    "    IndexSearcher searcher = getIndexSearcher();\n",
    "\n",
    "    for(String query: queries) {\n",
    "        printResults(query, searcher.search(parser.parse(query), 10));\n",
    "        System.out.println();\n",
    "    }\n",
    "}\n",
    "\n",
    "void searchQuery(Query query) throws IOException {\n",
    "    IndexSearcher searcher = getIndexSearcher();\n",
    "    TopDocs results = searcher.search(query, 10);\n",
    "    printResults(query.toString(), results);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First we perform some generic queries with keywords only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: star wars\n",
      "  #    id  Score   Year Runtime Rating   Title\n",
      "  1    29   4.53   1977     121    8.6   Star Wars\n",
      "  2   109   4.00   1983     131    8.3   Star Wars: Episode VI - Return of the Jedi\n",
      "  3    54   2.94   2017     125    8.4   Ayla: The Daughter of War\n",
      "  4   746   2.94   2013     132    7.7   Star Trek Into Darkness\n",
      "  5   182   2.93   1961     179    8.2   Judgment at Nuremberg\n",
      "  6   747   2.89   2015     137    7.7   Beasts of No Nation\n",
      "  7   955   2.85   1998     170    7.6   The Thin Red Line\n",
      "  8   278   2.79   1978     183    8.1   The Deer Hunter\n",
      "  9   461   2.79   1930     152    8.0   All Quiet on the Western Front\n",
      " 10   542   2.71   1970     172    7.9   Patton\n",
      "\n",
      "\n",
      "Query: drama morgan freeman\n",
      "  #    id  Score   Year Runtime Rating   Title\n",
      "  1     0   4.51   1994     142    9.3   The Shawshank Redemption\n",
      "  2   167   4.47   1992     130    8.2   Unforgiven\n",
      "  3   234   4.47   2004     132    8.1   Million Dollar Baby\n",
      "  4   673   4.45   1989     122    7.8   Glory\n",
      "  5   768   4.45   2006     110    7.7   Lucky Number Slevin\n",
      "  6   922   4.45   2007     114    7.6   Gone Baby Gone\n",
      "  7    27   4.25   1995     127    8.6   Se7en\n",
      "  8   747   3.11   2015     137    7.7   Beasts of No Nation\n",
      "  9   176   3.01   1976     177    8.2   The Message\n",
      " 10   814   2.80   1995      99    7.7   Do lok tin si\n",
      "\n",
      "\n",
      "Query: comedy\n",
      "  #    id  Score   Year Runtime Rating   Title\n",
      "  1   687   3.75   1982     109    7.8   The King of Comedy\n",
      "  2   972   3.27   1991      99    7.6   Delicatessen\n",
      "  3   754   3.17   2009      95    7.7   (500) Days of Summer\n",
      "  4   907   2.99   2011     100    7.6   50/50\n",
      "  5   274   2.97   1982     188    8.1   Fanny och Alexander\n",
      "  6    78   0.89   1964      95    8.4   Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb\n",
      "  7   277   0.89   1979      94    8.1   Life of Brian\n",
      "  8   417   0.89   1974     106    8.0   Young Frankenstein\n",
      "  9   539   0.89   1972     102    7.9   Le charme discret de la bourgeoisie\n",
      " 10   679   0.89   1986     103    7.8   Ferris Bueller's Day Off\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "searchExamples(getQueryParser(), new String[]{\n",
    "    \"star wars\", \n",
    "    \"drama morgan freeman\", \n",
    "    \"comedy\"\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: genre:drama actors:morgan actors:freeman\n",
      "  #    id  Score   Year Runtime Rating   Title\n",
      "  1     0   4.51   1994     142    9.3   The Shawshank Redemption\n",
      "  2   167   4.47   1992     130    8.2   Unforgiven\n",
      "  3   234   4.47   2004     132    8.1   Million Dollar Baby\n",
      "  4   673   4.45   1989     122    7.8   Glory\n",
      "  5   768   4.45   2006     110    7.7   Lucky Number Slevin\n",
      "  6   922   4.45   2007     114    7.6   Gone Baby Gone\n",
      "  7    27   4.25   1995     127    8.6   Se7en\n",
      "  8   311   2.36   1940      99    8.1   The Shop Around the Corner\n",
      "  9   609   2.08   2013     161    7.8   The Hobbit: The Desolation of Smaug\n",
      " 10   618   2.08   2012     169    7.8   The Hobbit: An Unexpected Journey\n",
      "\n",
      "\n",
      "Query: genre:comedy\n",
      "  #    id  Score   Year Runtime Rating   Title\n",
      "  1    78   0.89   1964      95    8.4   Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb\n",
      "  2   277   0.89   1979      94    8.1   Life of Brian\n",
      "  3   417   0.89   1974     106    8.0   Young Frankenstein\n",
      "  4   539   0.89   1972     102    7.9   Le charme discret de la bourgeoisie\n",
      "  5   679   0.89   1986     103    7.8   Ferris Bueller's Day Off\n",
      "  6   750   0.89   2009     100    7.7   The Hangover\n",
      "  7   800   0.89   1999      89    7.7   Office Space\n",
      "  8   808   0.89   1998      80    7.7   Le dîner de cons\n",
      "  9   816   0.89   1994      92    7.7   Clerks\n",
      " 10   837   0.89   1983      79    7.7   Zelig\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "searchExamples(getQueryParser(), new String[]{\n",
    "    \"genre:drama actors:morgan actors:freeman\", \n",
    "    \"genre:comedy\",\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: title:leon\n",
      "  #    id  Score   Year Runtime Rating   Title\n",
      "  1    42   3.84   1994     110    8.5   Leon\n",
      "\n",
      "\n",
      "Query: title:l?on\n",
      "  #    id  Score   Year Runtime Rating   Title\n",
      "  1    42   1.00   1994     110    8.5   Leon\n",
      "  2    43   1.00   1994      88    8.5   The Lion King\n",
      "  3   328   1.00   2016     118    8.0   Lion\n",
      "  4   545   1.00   1968     134    7.9   The Lion in Winter\n",
      "\n",
      "\n",
      "Query: title:leon~0.5\n",
      "  #    id  Score   Year Runtime Rating   Title\n",
      "  1    42   2.36   1994     110    8.5   Leon\n",
      "  2   328   1.77   2016     118    8.0   Lion\n",
      "  3    43   1.44   1994      88    8.5   The Lion King\n",
      "  4   545   1.44   1968     134    7.9   The Lion in Winter\n",
      "  5   486   1.18   2009      97    7.9   Moon\n",
      "  6   620   1.18   2007     123    7.8   Atonement\n",
      "  7   284   0.96   1973     102    8.1   Paper Moon\n",
      "  8   297   0.96   1960      89    8.1   Jungfrukällan\n",
      "  9   389   0.96   1999      86    8.0   The Iron Giant\n",
      " 10   448   0.96   1950      94    8.0   In a Lonely Place\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "searchExamples(getQueryParser(), new String[]{\n",
    "    \"title:leon\",\n",
    "    \"title:l?on\",\n",
    "    \"title:leon~0.5\",\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: title:{a TO b}\n",
      "  #    id  Score   Year Runtime Rating   Title\n",
      "  1     4   1.00   1957      96    9.0   12 Angry Men\n",
      "  2    40   1.00   1998     119    8.5   American History X\n",
      "  3    54   1.00   2017     125    8.4   Ayla: The Daughter of War\n",
      "  4    59   1.00   2019     181    8.4   Avengers: Endgame\n",
      "  5    60   1.00   2018     149    8.4   Avengers: Infinity War\n",
      "  6    71   1.00   1984     229    8.4   Once Upon a Time in America\n",
      "  7    72   1.00   1981     115    8.4   Raiders of the Lost Ark\n",
      "  8    74   1.00   1979     147    8.4   Apocalypse Now\n",
      "  9    75   1.00   1979     117    8.4   Alien\n",
      " 10    76   1.00   1971     122    8.4   Anand\n",
      "\n",
      "\n",
      "Query: year:{1990 TO 2000}\n",
      "  #    id  Score   Year Runtime Rating   Title\n",
      "  1     0   1.00   1994     142    9.3   The Shawshank Redemption\n",
      "  2     6   1.00   1994     154    8.9   Pulp Fiction\n",
      "  3     7   1.00   1993     195    8.9   Schindler's List\n",
      "  4     9   1.00   1999     139    8.8   Fight Club\n",
      "  5    11   1.00   1994     142    8.8   Forrest Gump\n",
      "  6    14   1.00   1999     136    8.7   The Matrix\n",
      "  7    24   1.00   1998     169    8.6   Saving Private Ryan\n",
      "  8    25   1.00   1999     189    8.6   The Green Mile\n",
      "  9    26   1.00   1997     116    8.6   La vita è bella\n",
      " 10    27   1.00   1995     127    8.6   Se7en\n",
      "\n",
      "\n",
      "Query: year:1994\n",
      "  #    id  Score   Year Runtime Rating   Title\n",
      "  1     0   1.96   1994     142    9.3   The Shawshank Redemption\n",
      "  2     6   1.96   1994     154    8.9   Pulp Fiction\n",
      "  3    11   1.96   1994     142    8.8   Forrest Gump\n",
      "  4    42   1.96   1994     110    8.5   Leon\n",
      "  5    43   1.96   1994      88    8.5   The Lion King\n",
      "  6   166   1.96   1994     160    8.2   Andaz Apna Apna\n",
      "  7   260   1.96   1994      99    8.1   Trois couleurs: Rouge\n",
      "  8   261   1.96   1994     102    8.1   Chung Hing sam lam\n",
      "  9   519   1.96   1994     102    7.9   Once Were Warriors\n",
      " 10   657   1.96   1994     127    7.8   Ed Wood\n",
      "\n",
      "\n",
      "Query: runtime:142\n",
      "  #    id  Score   Year Runtime Rating   Title\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "searchExamples(getQueryParser(), new String[]{\n",
    "    \"title:{a TO b}\",\n",
    "    \"year:{1990 TO 2000}\",\n",
    "    \"year:1994\",\n",
    "    \"runtime:142\"\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: #runtime:[142 TO 142] actors:morgan\n",
      "  #    id  Score   Year Runtime Rating   Title\n",
      "  1     0   2.22   1994     142    9.3   The Shawshank Redemption\n",
      "  2    11   0.00   1994     142    8.8   Forrest Gump\n",
      "  3   105   0.00   1985     142    8.3   Idi i smotri\n",
      "  4   169   0.00   1988     142    8.2   Dom za vesanje\n",
      "  5   506   0.00   2004     142    7.9   Harry Potter and the Prisoner of Azkaban\n",
      "  6   890   0.00   2015     142    7.6   Bridge of Spies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var query = new BooleanQuery.Builder()\n",
    "        // .add(IntField.newExactQuery(\"runtime\", 142), Occur.MUST)\n",
    "        // .add(IntField.newExactQuery(\"runtime\", 142), Occur.SHOULD)\n",
    "        .add(IntField.newExactQuery(\"runtime\", 142), Occur.FILTER)\n",
    "        .add(new TermQuery(new Term(\"actors\", \"morgan\")), Occur.SHOULD)\n",
    "        .build();\n",
    "\n",
    "searchQuery(query);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: #runtime:[120 TO 180] #year:[1990 TO 2000} actors:morgan\n",
      "  #    id  Score   Year Runtime Rating   Title\n",
      "  1     0   2.22   1994     142    9.3   The Shawshank Redemption\n",
      "  2   167   2.22   1992     130    8.2   Unforgiven\n",
      "  3    27   2.12   1995     127    8.6   Se7en\n",
      "  4     6   0.00   1994     154    8.9   Pulp Fiction\n",
      "  5     9   0.00   1999     139    8.8   Fight Club\n",
      "  6    11   0.00   1994     142    8.8   Forrest Gump\n",
      "  7    14   0.00   1999     136    8.7   The Matrix\n",
      "  8    15   0.00   1990     146    8.7   Goodfellas\n",
      "  9    24   0.00   1998     169    8.6   Saving Private Ryan\n",
      " 10    44   0.00   1991     137    8.5   Terminator 2: Judgment Day\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var query = new BooleanQuery.Builder()\n",
    "        .add(IntField.newRangeQuery(\"runtime\", 120, 180), Occur.FILTER)\n",
    "        .add(TermRangeQuery.newStringRange(\"year\", \"1990\", \"2000\", true, false), Occur.FILTER)\n",
    "        .add(new TermQuery(new Term(\"actors\", \"morgan\")), Occur.SHOULD)\n",
    "        .build();\n",
    "\n",
    "searchQuery(query);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: +title:star genre:action\n",
      "  #    id  Score   Year Runtime Rating   Title\n",
      "  1    29   2.95   1977     121    8.6   Star Wars\n",
      "  2   493   2.86   2009     127    7.9   Star Trek\n",
      "  3   746   2.51   2013     132    7.7   Star Trek Into Darkness\n",
      "  4   903   2.24   2018     136    7.6   A Star Is Born\n",
      "  5   839   2.05   1982     113    7.7   Star Trek II: The Wrath of Khan\n",
      "  6   109   1.99   1983     131    8.3   Star Wars: Episode VI - Return of the Jedi\n",
      "  7   477   1.90   2015     138    7.9   Star Wars: Episode VII - The Force Awakens\n",
      "  8   731   1.88   2014     126    7.7   The Fault in Our Stars\n",
      "  9    16   1.87   1980     124    8.7   Star Wars: Episode V - The Empire Strikes Back\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var query = new BooleanQuery.Builder()\n",
    "        .add(new TermQuery(new Term(\"title\", \"star\")), Occur.MUST)\n",
    "        .add(new TermQuery(new Term(\"genre\", \"action\")), Occur.SHOULD)\n",
    "        .build();\n",
    "\n",
    "searchQuery(query);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: #runtime:[120 TO 180] year:[1990 TO 2000} +title:shawshank (actors:morgan)^1.5\n",
      "  #    id  Score   Year Runtime Rating   Title\n",
      "  1     0   7.46   1994     142    9.3   The Shawshank Redemption\n",
      "\n",
      "7.4595942 = sum of:\n",
      "  0.0 = match on required clause, product of:\n",
      "    0.0 = # clause\n",
      "    1.0 = runtime:[120 TO 180]\n",
      "  1.0 = year:[1990 TO 2000}\n",
      "  3.1223383 = weight(title:shawshank in 0) [BM25Similarity], result of:\n",
      "    3.1223383 = score(freq=1.0), computed as boost * idf * tf from:\n",
      "      6.5022902 = idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "        1 = n, number of documents containing term\n",
      "        999 = N, total number of documents with field\n",
      "      0.48019058 = tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "        1.0 = freq, occurrences of term within document\n",
      "        1.2 = k1, term saturation parameter\n",
      "        0.75 = b, length normalization parameter\n",
      "        2.0 = dl, length of field\n",
      "        2.3003004 = avgdl, average length of field\n",
      "  3.337256 = weight(actors:morgan in 0) [BM25Similarity], result of:\n",
      "    3.337256 = score(freq=1.0), computed as boost * idf * tf from:\n",
      "      1.5 = boost\n",
      "      4.7686887 = idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "        8 = n, number of documents containing term\n",
      "        1000 = N, total number of documents with field\n",
      "      0.46655113 = tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "        1.0 = freq, occurrences of term within document\n",
      "        1.2 = k1, term saturation parameter\n",
      "        0.75 = b, length normalization parameter\n",
      "        8.0 = dl, length of field\n",
      "        8.537 = avgdl, average length of field\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var query = new BooleanQuery.Builder()\n",
    "        .add(IntField.newRangeQuery(\"runtime\", 120, 180), Occur.FILTER)\n",
    "        .add(TermRangeQuery.newStringRange(\"year\", \"1990\", \"2000\", true, false), Occur.SHOULD)\n",
    "        .add(new TermQuery(new Term(\"title\", \"shawshank\")), Occur.MUST)\n",
    "        .add(new BoostQuery(new TermQuery(new Term(\"actors\", \"morgan\")), 1.5f), Occur.SHOULD)\n",
    "        .build();\n",
    "        \n",
    "IndexSearcher searcher = getIndexSearcher();\n",
    "TopDocs results = searcher.search(query, 10);\n",
    "printResults(query.toString(), results);\n",
    "System.out.println(searcher.explain(query, results.scoreDocs[0].doc));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ganymede 2.1.1 (Java 17)",
   "language": "java",
   "name": "ganymede-2.1.1-java-17"
  },
  "language_info": {
   "file_extension": ".java",
   "mimetype": "text/x-java",
   "name": "java",
   "version": "11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
